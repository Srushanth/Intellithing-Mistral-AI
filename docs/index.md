# Introduction ğŸš€
---
## Overview ğŸ“
---
This project aims to deploy a [Mistral AI model](https://huggingface.co/mistralai) from [Hugging Face](https://huggingface.co/docs/transformers/main/model_doc/mistral) in an [Amazon Elastic Kubernetes Service (EKS)](https://docs.aws.amazon.com/eks/latest/userguide/what-is-eks.html) environment, create an API for it, and use the API in a [Gradio](https://www.gradio.app/) interface to test the model interactively. The project also requires the solution to have minimal standby servers and scale automatically as the requests or load increases. The project was assigned on *__11-Dec-2023__*.

The *__Mistral AI model__* is a *__large language model with 7 billion parameters__* that can generate text for various tasks. The EKS environment is a managed service that simplifies the deployment and management of Kubernetes clusters on AWS. The Gradio interface is a web-based GUI that allows users to interact with the model easily. The project uses various AWS services and tools, such as `VSCode`, `AWS CLI`, `EKS`, `ECS`, `EC2`, `VPC`, `IAM`, `K9S`, `eksctl`, and `Terraform` to create and configure the resources needed for the project.

## Project Structure ğŸ—‚
---
```
.
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ LICENSE
â”œâ”€â”€ Makefile
â”œâ”€â”€ README.md
â”œâ”€â”€ aws
â”‚   â”œâ”€â”€ 2048-pod.yaml
â”‚   â”œâ”€â”€ del-LoadBalancer.yaml
â”‚   â”œâ”€â”€ del-deployment.yaml
â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”œâ”€â”€ full.yaml
â”‚   â”œâ”€â”€ iam_policy.json
â”‚   â”œâ”€â”€ mygame-svc.yaml
â”‚   â”œâ”€â”€ sample.yml
â”‚   â””â”€â”€ service.yaml
â”œâ”€â”€ data
â”‚   â””â”€â”€ raw
â”‚       â””â”€â”€ Aurelien-Geron-Hands-On-Machine-Learning-with-Scikit-Learn-Keras-and-Tensorflow_-Concepts-Tools-and-Techniques-to-Build-Intelligent-Systems-OReilly-Media-2019.pdf
â”œâ”€â”€ docs
â”‚   â”œâ”€â”€ Introduction.md
â”‚   â””â”€â”€ index.md
â”œâ”€â”€ mkdocs.yml
â”œâ”€â”€ model_gguf
â”‚   â””â”€â”€ mistral-7b-instruct-v0.1.Q5_K_M.gguf
â”œâ”€â”€ notebooks
â”‚   â”œâ”€â”€ 1.download-model.ipynb
â”‚   â”œâ”€â”€ 1.gguf_model.ipynb
â”‚   â”œâ”€â”€ 1.guff-gradio.ipynb
â”‚   â”œâ”€â”€ 1.init.ipynb
â”‚   â”œâ”€â”€ gptq.ipynb
â”‚   â”œâ”€â”€ streamer.ipynb
â”‚   â””â”€â”€ test.ipynb
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ simple-bank
â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â””â”€â”€ service.yaml
â””â”€â”€ src
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ flagged
    â”œâ”€â”€ main-stream.py
    â”œâ”€â”€ main.py
    â””â”€â”€ streamer.py
```

## Clone and manage the repository ğŸ› 
---
1. Clone the repository to your local machine by running `git clone https://github.com/Srushanth/Intellithing-Mistral-AI`. ğŸ–¥
1. Create a new branch for your feature or bug fix by running `git checkout -b <branch_name>`. ğŸŒ¿
1. Make your changes to the code and test them locally. ğŸ§ª
1. Commit your changes to the branch by running `git add .` and `git commit -m "<commit_message>"`. 
    * **Note:** Use a meaningful and descriptive commit message that explains why you made the changes. ğŸ’¬
1. Push your branch to the remote repository by running `git push origin <branch_name>`. ğŸš€
1. Create a pull request to merge your branch to the master branch. 
    * **Note:** Use a clear and concise title and description for your pull request and assign a reviewer to approve it. ğŸ™‹â€â™‚ï¸
1. Wait for the reviewer to review your code and provide feedback. If there are any issues or suggestions, make the necessary changes and push them to the branch. ğŸ”„
1. Once the reviewer approves your pull request, merge it to the master branch. ğŸ‰

